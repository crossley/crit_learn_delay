\documentclass[doc, floatsintext]{apa7}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{sample.bib}
\setlength\bibhang{.15in}
\usepackage{amsmath}
\usepackage{float}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{setspace}
\setstretch{1.0}
\usepackage{caption}
\usepackage{gensymb}

\title{Is there a Criterion in Criterial Learning? \\ \vspace{.08in}
Insights from Studying Feedback Delays
}
\shorttitle{Criterial Learning}

\authorsnames[{1, 2}, {3}, {4}]{
    Matthew J. Crossley, 
    Benjamin O. Pelzer,
    F. Gregory Ashby
}

\authorsaffiliations{
    {School of Psychological Sciences, Macquarie University, Sydney, Australia}, 
    {Macquarie University Performance and Expertise Research Centre, Macquarie University, Sydney, Australia},
    {Independent Researcher},
    {Department of Psychological \& Brain Sciences, University of California, Santa Barbara}
    }

\abstract{
     The notion of a response criterion is ubiquitous in
     psychology, yet its cognitive and neural underpinnings
     remain poorly understood. Two experiments and extensive
     computational modeling were used to test between two
     strikingly different interpretations of the criterion.
     The traditional account is that decisions are made by
     comparing the stimulus value to a stored value of the
     criterion. A conceptually different interpretation is
     that learning instead is a process of associating
     responses with stimuli, and that the criterion is
     simply the hypothetical value that separates stimuli
     associated with contrasting responses. The experiments
     and modeling tested between these two interpretations
     by contrasting the effects on criterial learning of
     feedback delays versus increases in the duration of the
     intertrial interval in a one-dimensional
     category-learning task. The empirical results strongly
     suggested that human criterial learning is sensitive to
     feedback delay but not to the duration of the
     intertrial interval. The computational modeling showed
     that these results are compatible with a
     stimulus-response learning account, and incompatible
     with all versions of the stored-criterion account,
     except for the subset of these models that explicitly
     assume the criterial updating process is sensitive to
     feedback delay.
}

\authornote{Correspondence: Matthew J. Crossley, PhD,
  School of Psychological Sciences, Macquarie University,
  Australian Hearing Hub, 16 University Ave, Macquarie
  University, NSW 2109, Australia. Email:
  matthew.crossley@mq.edu.au 
}

\keywords{response criterion; criterial learning; associative learning; categorization; procedural learning}

\begin{document}
\maketitle 

\section{Introduction}
The notion of a response criterion is ubiquitous in
psychology. It is a key component of almost all decision
models. For example, the hypothesis that even YES-NO
detection decisions are determined by comparing the sensory
magnitude to a response criterion that is under the
observer's control, rather than to a fixed absolute
threshold, allowed signal detection theory to supplant
classical threshold theory as the dominant model in
psychophysics \parencite{GreenSwets1966}. All models that
include a response criterion assume its value is learned and
can shift if changes are made to instructions or payoffs. So
criterial learning is a fundamental component of almost all
decision-making models. Despite its importance, however, the
cognitive and neural mechanisms that underlie criterial
learning remain poorly understood.

This article addresses this shortcoming through a
combination of empirical data collection and computational
modeling. Specifically, our goal is to test between two
general possibilities. One is that the criterion is learned
in the sense that it is updated trial-by-trial and that its
current value is stored in memory. This is the hypothesis
implicitly assumed by most decision-making models (e.g.,
signal-detection theory). The second possibility is that the
criterion has no psychological meaning and learning instead
is of stimulus-response (SR) associations. According to this
account, the criterion is simply the sensory (or cognitive)
value that separates percepts associated with the
contrasting responses. For example, there is evidence that
procedural learning works in this way
\parencite{AshbyWaldron1999}.

Two independent variables that seem especially likely to
discriminate between these two alternatives are the duration
of the intertrial interval (ITI) and the delay between the
response and the feedback. If the value of a criterion is
updated following feedback and then held in memory until
needed again, then the longer it must be held in memory, the
more time there is for its value to drift. In other words,
there should be more criterial drift with long ITIs than
with short ITIs, and as a result, increasing the ITI should
impair performance. In contrast, if the criterion has no
psychological meaning and instead learning is of SR
associations, then learning should be impaired by increases
in feedback delay. The idea is that positive feedback
strengthens and negative feedback weakens recently active
synapses that associate a response with the presented
stimulus. As a result, increasing the feedback delay will
weaken the trace of recently active synapses, and therefore
reduce this type of SR learning. This model is supported by
many previous reports that feedback delays as short as 3 s
impair procedural learning much more than  declarative
learning that depends on executive attention and working
memory  \parencite{DunnEtAl2012, ell2009critrial,
MaddoxAshbyBohil2003, MaddoxIng2005,  Worthyetal2013}.

Our general approach is as follows. First, we establish an
empirical database by describing the results of two
experiments that report the results of manipulating ITI and
feedback delay on criterial learning. Although a variety of
different tasks could be used to study criterial learning,
the two experiments we describe used a one-dimensional
category-learning task. In such tasks, stimuli vary across
trials on two or more dimensions -- one relevant to
categorization and one or more that are irrelevant. The
observer's goal is to identify the relevant dimension and
learn the response criterion that maximizes accuracy. This
task has been used in hundreds of studies, and all current
models of performance in this task emphasize the role of
criterial learning.

In the first experiment, participants were explicitly
instructed about the relevant dimension, thereby isolating
criterial learning from rule selection and switching
processes. The results showed that increasing the feedback
delay impaired learning but increasing the ITI did not.
Experiment 2 used stimuli that varied on six binary-valued
dimensions and participants were not told which of these
dimensions was relevant to the categorization decision. The
observer's task was to discover the single relevant
dimension, but after this dimension was identified, no
criterial learning was required since there were two
categories and the stimuli had exactly two values on the
relevant dimension. Thus, Experiment 2 isolated rule
selection and switching from criterial learning. The results
showed that performance was unaffected either by increases
in feedback delay or ITI. These findings therefore suggest
that feedback delays impact criterial learning but not the
discovery of the relevant stimulus dimension. 

The results of Experiments 1 and 2 seem to suggest that
criterial learning is a form of procedural learning, even in
tasks that seem to rely on explicit, rule-based processes,
and therefore that the criterion is an emergent construct
with no psychological meaning. Before accepting this
conclusion however, it is important to ask whether some type
of criterion-learning model can account for these results.
To investigate this question, we developed a variety of
computational models of criterial learning of two different
types. Eight different models assumed the criterion is
learned and updated trial-by-trial. These were created by
factorially combining three different binary assumptions:
the percept drifts randomly over time (yes or no), the
criterion drifts randomly over time (yes or no), and the
updating of the criterion is sensitive to the feedback delay
(yes or no). Four different models assumed that learning is
of SR associations and that the criterion therefore has no
psychological meaning. These were created by factorially
combining two binary assumptions: the percept drifts
randomly over time (yes or no) and SR strengthening is
sensitive to feedback delay (yes or no). Next, using a
technique called parameter-space partitioning
\parencite{pitt2006global}, we investigated whether each
model could account for the qualitative results of
Experiments 1 and 2. The results of these analyses
reinforced the conclusion that criterial learning may have
strong associative underpinnings, even in tasks that appear
to rely on explicit, rule-based reasoning. 

\section{Experiment 1}
Experiment 1 used a one-dimensional category-learning task
to investigate how feedback delay and ITI affect criterial
learning. The stimuli in this experiment were circular
sine-wave gratings that varied across trials in bar width
and bar orientation. These stimuli were divided into two
categories according to their value on one of the two
dimensions. In other words, the optimal strategy was to set
a response criterion on the single relevant dimension, and
then choose a categorization response based on whether the
value of the presented stimulus on this dimension was larger
or smaller than the criterion value.  The experiment
isolated criterial learning by (1) explicitly instructing
participants about the relevant stimulus dimension and rule
structure (e.g., thick bars are ``A'', thin bars are ``B''),
and (2) eliminating all variability along the irrelevant
stimulus dimension. In other words, the instructions
identified the relevant stimulus dimension, and as a result,
the only learning required was criterial learning. 

Each participant practiced each of 14 one-dimensional
category-learning tasks, or problems, until they responded
correctly on 9 of the 10 previous trials, at which point the
problem changed. The 14 different category structures are
described in Figure \ref{fig_design_exp_1_space}. The
relevant dimension was bar thickness in problems 1 -- 7 and
bar angle in problems 8 -- 14. Each problem included stimuli
in two distinct clusters that varied over a restricted range
of the relevant dimension. Critically, the optimal criterion
value varied from problem-to-problem with respect to its
position within the stimulus range. For example, for some
problems the optimal criterion was below the midpoint of the
range and for other problems it was above the midpoint.
Feedback delay and ITI were varied across three conditions.
In the Delayed-Feedback condition, feedback was delayed
after the observer responded (by 3.5 s) and the ITI was
short (500 ms). In the Long-ITI condition, the feedback
delay was short (500 ms) and the ITI was long (3.5 s).
Finally, in the Control condition, feedback delay and the
ITI were both 500 ms.

\begin{figure}
  \centering
  \includegraphics[width=.5\textwidth]{../figures/fig_design_exp_1_space.png}
  \caption{
      Category sample space. Different colors represent
      different category problems. Dashed lines are category
      boundaries (criterion) and the surrounding solid lines
      mark the no-stimulus region in which no stimuli were
      sampled.
}
  \label{fig_design_exp_1_space}
\end{figure}

\subsection{Method}

\subsubsection{Apparatus}
All experiments were performed in a dimly lit room.
Participants sat approximately 24'' from a 17'' $\times$
11'' monitor running at a resolution of 1680 $\times$ 1050
pixels. Participants made category judgments by pressing the
`d' or `k' keys on a standard computer keyboard for `A' or
`B' choices, respectively. Stickers with bold print `A' or
`B' were placed on the appropriate keys.

\subsubsection{Stimuli and Categories}
Stimuli were circular sine-wave gratings that varied in bar
width and bar orientation, drawn from various 1-dimensional
uniform distributions specific to the current category
problem. We first defined an arbitrary 2-dimensional
$[0-100,0-100]$ stimulus space, and then split each
dimension of this space into 7 bins of width 14 units each.
Each $(x,y)$ pair from this arbitrary stimulus space was
converted to a grating according to the nonlinear
transformations defined by
\textcite{treutwein1989perceptual}, which roughly equate the
salience of each dimension. For details, see also
\textcite{CrossleyAshby2015}.

The structure of the various criterial-learning tasks is
illustrated in Figure \ref{fig_design_exp_1_space}. Each
criterial-learning problem was created by first selecting a
relevant dimension. This was spatial frequency for the
problems 1 through 7 and orientation for problems 8 through
14. We then randomly selected one of the 7 bins defined on
that dimension. Each bin was also associated with a
corresponding unique value on the irrelevant dimension. We
buffered the to-be-learned response criterion by 10\% of
total bin width on either side with a no-stimulus region.
Random uniform samples from the remaining eligible region of
each bin were then selected and presented to the participant
until 9 correct responses out of any 10 responses in a row
advanced the participant to the next problem. Note that
every category problem was a simple one-dimensional rule in
which optimal accuracy was 100\%.  Note also that the
relative location of the optimal response criterion varied
across problems.

\subsubsection{Procedure}
There were three conditions (described in detail in Table
\ref{conditions_exp_1}). In the Delayed-Feedback condition,
feedback was delayed 3.5 s after the response and the ITI
was 0.5 s. In the Long-ITI condition, feedback was delayed
0.5 s after the response and the ITI was 3.5 s. Finally, in
the Control condition, feedback was delayed 0.5 s after the
response and the ITI was 0.5 s.

Each participant completed a series of one-dimensional
category-learning tasks or problems, which are described in
Figure \ref{fig_design_exp_1_space}. Each problem included
stimuli in two distinct clusters that varied over a
restricted range of the relevant dimension. Critically, the
optimal criterion value varied from problem-to-problem with
respect to its position within this range. For example, for
some problems the optimal criterion was below the midpoint
of the range and for other problems it was above the
midpoint. 

Participants were explicitly told the relevant dimension for
each problem, as well as the generic response mapping (e.g.,
thick bars = ``A'', thin bars = ``B''). Figure
\ref{fig:trial} shows the structure of an example trial,
along with an example of a typical category structure. All
trials in every condition included a 500 ms fixation cross,
a response-terminated stimulus, a circular white-noise mask,
corrective feedback, and an inter-trial interval (ITI) that
varied according to condition. The text `Correct' was
displayed in centered, large green font after correct
responses, and the text `Incorrect' was displayed in
centered, large red font after incorrect responses.

Participants practiced each problem until they responded
correctly on 9 of the previous 10 trials. At this point, the
problem changed. Each participant completed as many problems
as possible in 512 trials or until they had been in the lab
for 60 minutes (including time to acquire consent and give
instructions), at which point the session was terminated.

\begin{figure}
  \centering
  \includegraphics[width=.5\textwidth]{../figures/fig_design_exp_1.png}
  \caption{
      Example trial and category problem. A) Events that
      occurred on each trial. B) An example of a typical
      category structure.
}
  \label{fig:trial}
\end{figure}

\begin{table}
    \caption{
        Durations (in s) of Trial Events in each Condition.
    }
    \label{conditions_exp_1}
    \begin{tabular}{c|cccc}
        Conditions & Stim & Mask & FB & ITI \\[0.5ex] \hline Control & RT & 0.5 &
        1.0 & 0.5 \\[0.5ex]
        \\[-1.5ex] Delayed Feedback &
        RT & 3.5 & 1.0 & 0.5 \\[0.5ex]   Long ITI & RT & 0.5 & 1.0 & 3.5
        \\[0.5ex]
    \end{tabular}
\end{table}

\subsubsection{Participants}
Fifty-nine participants participated in Experiment 1. All
were UCSB undergraduates and received course credit for
their participation. All had normal or corrected to normal
vision. We randomly assigned each participant to one of
three conditions (target $N>16$ per condition based on
similar previous research): Delayed Feedback ($N = 20$);
Long ITI ($N = 21$), Control ($ N = 17$). All participants
gave written informed consent before participating in the
study. All experimental protocols were approved by the
University of California at Santa Barbara Human Subjects
Committee in the Office of Research Development and
Administration.

\subsection{Results}
Both panels of Figure \ref{fig_mm_hist_1} show the same
relative frequency histogram of the trials-to-criterion
collapsed across all participants and conditions. The
histogram shows that the majority of participants were able
to learn each problem on average in less than 100 trials.
However, this histogram also shows that a subset of
participants required many more trials to learn each
problem. Given that participants were explicitly instructed
about the relevant dimension of each problem, the task was
relatively simple and as a result, it seems likely that the
participants represented by the tails of this distribution
did not pay attention to the instructions, were not
motivated to learn the task, were distracted by other
factors, or should be considered outliers for some other
reason. In our experience, it is not unusual for a small
subset of participants to perform very poorly in experiments
of this kind. This typically reflects a lack of engagement
or misunderstanding of the task instructions rather than an
inability to perform the task itself.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{../figures/fig_exp_1_mm_trunc_exgauss_compare.png}
  \caption{
      Relative frequency histogram of the
      trials-to-criterion collapsed across all three
      conditions and participants in Experiment 1. The left
      panel shows the best-fitting single ExGaussian
      distribution and the right panel shows the
      best-fitting two-component ExGaussian mixture model.
      In the right panel, the blue dashed line is the first
      higher performance component, the orange dashed line
      is the second lower performance component.       The
      gray solid line is the mixture distribution that
      combines these two components. Rug plots along the
      x-axes show the individual data      colored by their
      assignment to either the higher or lower performance
      component. The two-component model provided a
      significantly better fit according to AIC, BIC, and a
      likelihood ratio test.
}
  \label{fig_mm_hist_1}
\end{figure}

We identified and removed from further analyses these
outlier participants using the following algorithm. First,
we modeled the distribution shown in Figure
\ref{fig_mm_hist_1} using a mixture of two ExGaussian
distributions,\footnote{The ExGaussian is the distribution
of the sum of two independent random variables -- one with
an exponential distribution and one with a normal or
Gaussian distribution.} each truncated to the range of
possible trials-to-criterion values (i.e., $[9,512]$). The
first distribution or component was assumed to model
performance of participants with a relatively low mean
number of trials-to-criterion, whereas the second component
was assumed to identify outlier participants. We estimated
parameters of this model using maximum likelihood estimation
with proper normalization on the tasks bounded support and
compared them via the AIC and BIC goodness-of-fit
statistics, and a parametric bootstrap likelihood-ratio
test. We then compared the fit of this two-component model
to a single-component ExGaussian model using AIC and BIC,
both of which indicated a better fit for the two-component
model ($\mathrm{AIC}_1=692.15$ vs. $\mathrm{AIC}_2=652.81$;
$\mathrm{BIC}_1=698.33$ vs. $\mathrm{BIC}_2=667.23$). The
bootstrap likelihood-ratio test also confirmed that the
two-component model provided a significantly better fit than
the one-component model ($D=42.84$, $p_{\text{boot}}\approx
.01$). Next, for each participant, we used the
best-fitting two component model to compute the likelihood
that their performance was best described by each component.
Participants whose data were estimated to most likely belong
to the low-performance distribution were classified as
outliers and excluded from further analysis. After making
these exclusions, we were left with the following sample
sizes:  Control condition ($ N = 11$); Delayed-Feedback
condition ($N = 14$); Long-ITI condition ($N = 17$).

Figure \ref{fig_exp_1_t2c}A shows the mean
trials-to-criterion for all non-excluded participants in
each condition of Experiment 1.  A one-way ANOVA revealed a
significant effect of condition ($F(2, 39) = 6.17$, $p <
.01$, $\eta^2 = .24$) and planned comparisons revealed that
performance in the Delayed-Feedback condition was
significantly worse than in either the Control condition
($t(23.00) = 2.70$, $p < .05$, $d=1.06$) or the Long-ITI
condition ($t(20.96) = 2.94$, $p < .01$, $d=1.10$).
Performance in the Control and Long-ITI conditions did not
differ significantly from each other ($t(17.99) = .22$, $p
= .83$, $d=.09$). \footnote{Including the excluded outliers
in these analyses eliminates the difference between
conditions.}

Figure \ref{fig_exp_1_t2c}B shows the mean number of
problems solved in each condition of Experiment 1. A one-way
ANOVA revealed a significant effect of condition ($F(2, 39)
= 5.77$, $p < .01$, $\eta^2 = .23$). Planned comparisons
revealed that performance in the Delayed-Feedback condition
was significantly worse than in the Control condition
($t(18.54) = -3.28$, $p < .01$, $d=-1.21$) and worse than in
the Long ITI condition ($t(21.60) = -2.14$, $p < .05$,
$d=-.80$).  Performance in the Control and Long-ITI
conditions did not differ significantly from each other
($t(25.97) = -1.50$, $p=.15$, $d=-.53$).

\begin{figure}
  \centering
  \includegraphics[width=.8\textwidth]{../figures/fig_exp_1_t2c.png}
    \caption{
        \textbf{A}: Mean trials-to-criterion in each
        condition of Experiment 1. Error bars are standard
        errors of the mean.
        %
        \textbf{B}: Mean number of problems solved in each
        condition of Experiment 1. Error bars are standard
        errors of the mean.
}
  \label{fig_exp_1_t2c}
\end{figure}

\section{Experiment 2}
According to a popular model of one-dimensional rule-based
category learning \parencite[i.e.,
COVIS;][]{AshbyCOVIS1998}, successful learning requires at
least three separate cognitive processes: selecting a rule
for testing, switching from one candidate rule to another
(following negative feedback), and criterial learning.
Experiment 1 isolated criterial learning from this set.
Experiment 2 complements Experiment 1 by using a task that
required rule selection and rule switching, but no criterial
learning. 

Experiment 2 used colored geometric figures as stimuli,
which varied across trials on six binary dimensions (i.e.,
see Figure \ref{fig_design_exp_2}B). As in Experiment 1,
only one dimension was relevant. Unlike Experiment 1,
however, participants were given no instruction as to which
dimension was relevant. Therefore, this task required
participants to discover the relevant dimension. However,
after this dimension was identified, no criterial learning
was required because each stimulus always had one of two
possible values on the relevant dimension and participants
were instructed that there were two categories. Experiment 2
was therefore designed to test whether the impaired learning
that we observed in Experiment 1 when the feedback was
delayed can be attributed principally to criterial learning
or whether it could be due to some more general
category-learning process.

\subsection{Method}

\subsubsection{Apparatus}
The apparatus was the same as in Experiment 1.

\subsubsection{Stimuli and Categories}
The stimuli consisted of colored geometric figures presented
on a colored background. These varied across six binary
dimensions: the number of items (either one or two), the
size of the items (small or large), the color of the items
(yellow or blue), the shape of the items (circle or square),
the texture of the background (smooth or rough), and the
orientation of the background (horizontal or tilted by 20
degrees). This combination resulted in a total of 64 unique
stimuli ($2^6$). An example trial and stimuli are shown in
Figure \ref{fig_design_exp_2}. In all conditions, the order
of stimulus presentation was fully randomized for each
participant, and the relevant dimension for each problem was
selected randomly without replacement from the set of six
dimensions.

\begin{figure}
  \centering
  \includegraphics[width=.5\textwidth]{../figures/fig_design_exp_2.png}
  \caption{
      \textbf{A:} An example trial from Experiment 2.
      \textbf{B:} Eight example stimuli (out of 64 total
      stimuli) from a possible one-dimensional rule problem.
      In this case the correct rule is `A' if the shape
      color is yellow and `B' if the shape color is blue.
      The solid line represents the category boundary.
}
  \label{fig_design_exp_2}
\end{figure}

\subsubsection{Procedure}
Participants received detailed instructions about the task.
However, unlike in Experiment 1, they were not informed of
the relevant dimension or the correct rule. The trial timing
for the Delayed-Feedback and Long-ITI conditions in
Experiment 2 were the same as in Experiment 1. Experiment 2
did not include a condition that was analogous to the
Control condition of Experiment 1. Participants practiced
each problem until they responded correctly on 12
consecutive trials. At this point, the problem changed. Each
participant completed as many problems as possible in 600
trials or until they had been in the lab for 30 minutes
(including time to acquire consent and give instructions),
at which point the session was terminated.

\subsubsection{Participants}
Thirty-four participants participated in Experiment 2. All
were Macquarie University undergraduates and received course
credit for their participation. All had normal or corrected
to normal vision. We randomly assigned each participant to
one of two conditions: Delayed Feedback ($N = 17$) or Long
ITI ($N = 17$).  All participants gave written informed
consent before participating in the study. All experimental
protocols were approved by the Macquarie University Human
Research Ethics Committee (protocol number: 52020339922086). 

\subsection{Results}
Figure \ref{fig_mm_hist_2} shows the trials-to-criterion
relative frequency histogram collapsed across participants
and conditions. As in Experiment 1, the histogram shows that
the majority of participants were able to learn each problem
in well under 100 trials. Unlike Experiment 1, however,
there were no highly suspicious outliers in this data set.
Nevertheless, for symmetry with Experiment 1, we performed
the same ExGaussian mixture model analysis as used there.
The two-component model provided a slightly smaller AIC
value (317.07 vs 325.38), and a slightly smaller BIC value
(327.75 vs 329.96). The bootstrap likelihood-ratio test was
not significant ($D = 13.05, p_{\text{boot}} \approx .08$).
Given the weaker evidence for multiple components in this
data set compared to Experiment 1, and the fact that there
were no obvious outliers in this data set, we concluded that
there was insufficient evidence to justify excluding any
participants from further analysis.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{../figures/fig_exp_2_mm_trunc_exgauss_compare.png}
  \caption{
      Relative frequency histogram of the
      trials-to-criterion collapsed across all participants
      and conditions in Experiment 2. The left panel shows
      the best fitting one-component ExGaussian
      distribution, and the right panel shows the two
      components of the best-fitting two component
      ExGaussian mixture model.
}
  \label{fig_mm_hist_2}
\end{figure}

Figure \ref{fig_exp_2_t2c}A shows the mean
trials-to-criterion in each condition of Experiment 2. An
independent-samples t-test revealed no significant effect of
condition ($t(32.0)=1.37$, $p = .18$, $d = .47$).  The mean
number of problems solved by each participant is shown in
Figure \ref{fig_exp_2_t2c}B. An independent-samples t-test
revealed no significant effect of condition ($t(32.0) =
-1.99$, $p = .06$, $d = -.68$).

\begin{figure}
  \centering
  \includegraphics[width=.8\textwidth]{../figures/fig_exp_2_t2c.png}
    \caption{
        \textbf{A}: Mean trials to criterion in each
        condition of Experiment 2. Error bars are standard
        errors of the mean.
        %
        \textbf{B}: Mean number of problems solved in each
        condition of Experiment 2. Error bars are standard
        errors of the mean.
}
  \label{fig_exp_2_t2c}
\end{figure}

\subsection{Discussion of Experiments 1 and 2}
Experiment 1 showed that a short feedback delay of only 3.5
s slowed criterial learning. In contrast, increasing the ITI
from 500 ms to 3.5 s had no effect on learning. The task we
used was one-dimensional category learning, but we isolated
criterial learning by instructing participants about the
optimal strategy. Specifically, we told them which stimulus
dimension was relevant and that there was no trial-by-trial
variability on the irrelevant dimension. Although these
results strongly suggest that the feedback delay had its
interfering effects on criterial learning, Experiment 2 was
designed to complement this inference. The goal here was to
examine the effects of the same feedback delays and ITIs on
performance in a one-dimensional category-learning task that
did not require any criterial learning, but did require
category-learning processes that are thought to mediate rule
discovery (e.g., rule selection and switching). If the
feedback delay effects observed in Experiment 1 were acting
on some general category-learning skill then we should have
seen the same interfering effects of feedback delay in
Experiment 2. However, if the feedback-delay interference of
Experiment 1 was operating selectively on criterial
learning, then it should disappear in Experiment 2, since no
criterial learning was required.  Our results strongly
supported this latter prediction.  Therefore, Experiments 1
and 2 together strongly suggest that criterial learning is
impaired by feedback delays and is relatively unaffected by
the length of the ITI.

Whereas the results of Experiment 1 seem clear, the
Experiment 2 results are weaker since they suggest a null
result. Although it impossible to rule out the possibility
that Experiment 2 missed some small effect of feedback delay
due to insufficient power, the null results found there are
consistent with a wide variety of other evidence. In
particular, a variety of other studies have reported that
feedback delays of up to 10 s do not significantly slow
one-dimensional rule-based learning \parencite{DunnEtAl2012,
    ell2009critrial, MaddoxAshbyBohil2003, MaddoxIng2005,
Worthyetal2013}. In addition, many studies have reported
evidence that one-dimensional rule-based learning recruits
working memory and executive attention, but not procedural
learning \parencite[for reviews, see,
e.g.,][]{AshbySmithRosedahl2020, AshbyValentin2017}. So the
results of Experiment 2 are consistent with all of these
studies. On the other hand, several of these feedback-delay
studies did not use binary-valued stimulus dimensions, so
some criterial learning was required. If so, then why did
they all report no effect of feedback delay? It is important
to note that criterial learning was not the focus of any of
these studies, and as a result, in all of these previous
studies the optimal criterion was always set exactly midway
between the category prototypes, which makes criterial
learning trivial. For example, under these conditions,
criterial learning might not even require feedback. The
unsupervised category-learning experiments reported by
\textcite{ashby1999dominance} provide strong support for
this because all of their rule-based participants learned
the correct criterion (which was midway between the category
means), even though the task was completely unsupervised.

We know of only one previous study that reported impaired
one-dimensional rule-based category learning when feedback
was delayed \parencite{ell2009critrial}. However, in this
study, a feedback delay only impaired performance in a
condition with four contrasting categories that required
learning three different response criteria. So this task was
considerably more complex than any of the other
feedback-delay studies, which all used two contrasting
categories that required the learning of only one response
criterion. 

One other study with similar goals to ours studied how
manipulations of category base rates affect criterial
learning in one-dimensional rule-based categorization.
Specifically, \textcite{bohil2014implicit} reported that
changes in criterion placement in response to changes in
base rate were diminished when feedback was delayed (and
also by observational training). These results are
consistent with our findings. However, because they were
obtained by manipulating base rates, it is difficult to
conclude that the delay affected criterial learning,
\emph{per se}. For example, consider a simple two-stage
model in which the first stage learns the base rates and the
second stage uses what the first stage learned to adjust the
response criterion appropriately. The
\textcite{bohil2014implicit} results are also consistent
with the hypothesis that the feedback delay impaired the
first of these stages but not the second. Our results
strongly suggest that feedback delays impair criterial
learning (and therefore the second of these hypothetical
stages).

\section{New Computational Models of Criterial Learning}
The results of Experiments 1 and 2 seem to suggest that
criterial learning is a form of procedural learning, which
previous research suggests is of SR associations
\parencite{AshbyWaldron1999, CasaleEtAl2012}. If so, then
the criterion is simply the sensory, perceptual, or
cognitive value that separates representations associated
with contrasting responses. However, before accepting this
conclusion, it is important to ask whether our results might
also be compatible with an account in which the criterion is
held is some form of working or short-term memory and
updated trial by trial. 

To address this question, we developed computational models
of criterial learning within two broad architectures and
examined their sensitivity to ITI duration and feedback
delay. The architectures differed in whether they assume
that the response criterion is explicitly represented in
memory. In the first architecture, the criterion is stored
in memory, and responses are generated by comparing the
current percept with this stored referent. The criterion is
updated after error feedback using a gradient-descent rule.
Models in this class can exhibit sensitivity to ITI and
feedback delay in three distinct ways: (1) perceptual drift,
where stimulus representations change over time, (2)
criterial drift, where the stored criterion shifts over
time, and (3) updating that is sensitive to feedback delays,
where the magnitude of criterion updates decreases with
longer feedback delays. In the second architecture, no
explicit criterion is stored. Instead, reinforcement
learning forms direct stimulus--response associations that
drive performance.  Sensitivity to ITI and feedback delay
arise from perceptual drift and/or delay-sensitive updating,
but criterial drift is not possible since no criterion is
represented.

For each of these models, denote the time of stimulus
presentation on the current trial by T$_\text{S}$, the
response time by T$_\text{R}$, the time when feedback is
displayed by T$_\text{F}$, and the time when the stimulus
that begins the next trial is displayed by T$_{\text{S}^+}$.
Then note that the feedback delay equals $\text{t}_\text{FD}
= \text{T}_\text{F} - \text{T}_\text{R}$ and the duration of
the ITI equals $\text{t}_\text{ITI} = \text{T}_{\text{S}^+}
- \text{T}_\text{F}$.

\subsection{Models that assume a stored criterion}
These models assume that the observer constructs a response
criterion, maintains it in memory, and makes
decisions by comparing the percept to this criterion. They
may further posit that both the stored criterion and the
perceived stimulus value drift over time, with the extent of
drift increasing both within a trial and across consecutive
trials. In addition, they may assume that the learning rate
for updating the criterion decreases as the feedback delay
increases.

Let $x_n(t)$ and $c_n(t)$ denote the values of the percept
and the criterion, respectively, on trial $n$ at time $t$.
Then the decision rule on trial $n$ is:
\begin{equation}
  \text{Respond } R_n =
  \begin{cases}
    \text{A}, & \text{if ~} x_n(\text{T}_\text{S}) \leq c_n(\text{T}_\text{S})  \\
    \text{B}, & \text{if ~} x_n(\text{T}_\text{S}) > c_n(\text{T}_\text{S}).
  \end{cases}
  \label{eq:DR}
\end{equation}
Note that this equation indicates that the response is made
immediately upon stimulus presentation. We therefore are not
explicitly modeling the time-extended cognitive processes
that govern evidence accumulation and the corresponding
response time.

If positive feedback is received, then the value of the
criterion remains unchanged for the next trial (except for
drift -- see equation \ref{eq:criterion}).  The rationale
here is that if the response is correct, then the observer
has effectively gained zero information about how their
criterion should be modified.  If negative feedback is
received, then the criterion is modified according to the
standard model
\parencite{SuttonBarto1998}:
\begin{equation}
c_n(\text{T}_\text{F}+ \Delta_t) = c_n(\text{T}_\text{F}) + \frac{\alpha}{t_{FD}} [x_n(\text{T}_\text{F}) - c_n(\text{T}_\text{F})],
\label{RL}
\end{equation}
where $\alpha$ is a learning-rate parameter, and $\Delta_t$
is the time it takes to complete the updating.  It is
straightforward to show that the iterative equation \ref{RL}
is equivalent to computing a weighted mean (weighted by
recency) of the values of all percepts that occur on error
trials \parencite[e.g.,][]{Ashby2017}. This updating rule
will gradually converge on the optimal criterion value
(i.e., the value of the criterion that maximizes accuracy).  

The term $\alpha/t_{FD}$ captures the notion that the
magnitude of the update decreases as the feedback delay
increases.  As a result, when feedback is delayed, the
system becomes less responsive to errors, leading to slower
learning compared to immediate feedback conditions. However,
since this model is consistent with the idea that criterial
learning relies on working memory -- and the available
evidence suggests that logical reasoning and working memory
are unaffected by feedback delays of several seconds
\parencite[e.g., in one-dimensional rule-based category
learning tasks;][]{ell2009critrial, MaddoxAshbyBohil2003,
MaddoxIng2005} -- the learning process described in equation
\ref{RL} likewise may be unaffected by feedback delay. We
therefore also investigated a version of the model in which
the term $\alpha/t_{FD}$ is replaced by $\alpha$, making the
learning rate independent of feedback delay.

This model further assumes that both the stimulus and the
criterion representations may drift randomly throughout the
duration of time they are maintained in working memory. The
representation of the criterion must always be maintained in
working memory, whereas drift in the stimulus representation
affects performance up until the feedback is presented, but
not afterwards (i.e., because the equation \ref{RL} updating
rule depends on the value of the current stimulus
representation). We modeled the drift in both the criterion
and the percept by adding white noise to their initial
values. Specifically, we assumed that for all
$t>\text{T}_\text{S}$
\begin{equation}
  c_n(t) = c_n(\text{T}_\text{S}) + \eta_c \epsilon(t),
  \label{eq:criterion}
\end{equation}
and
\begin{equation}
  x_n(t) = x_n(\text{T}_\text{S}) + \eta_x \epsilon(t),
  \label{eq:percept}
\end{equation}
where $\epsilon(t)$ is white noise and $\eta_c$ and $\eta_x$
are parameters that determine the amount of drift over time.
Note that these parameters are permitted to be equal to
zero, which is equivalent to assuming that the criterion
and/or the percept do not drift over time at all.

This model predicts that between the time of stimulus
presentation and feedback, the response criterion will drift
randomly. The amount of drift during this time will be
normally distributed with mean zero and variance
$\text{t}_\text{FD} \eta_c^2$. Similarly, the amount of
criterial drift after the updating that follows feedback and
the presentation of the stimulus on the next trial will also
be normally distributed with mean zero, but now with
variance $(\text{t}_\text{ITI}) \eta_c^2$. Predictions for
the percept are similar. Specifically, the amount of drift
between stimulus presentation and feedback will be normally
distributed with mean zero and variance $\text{t}_\text{FD}
\eta_x^2$.

\subsection{Models that assume no criterion}
A qualitatively different class of models, based on an
actor-critic architecture \parencite{SuttonBarto1998},
assume that learning is a process of associating each
stimulus with a response via reinforcement learning. These
models do not include an explicit representation of the
response criterion. Rather the criterion is simply the
mental representation that separates percepts associated
with contrasting responses. 

In this class of models, the perceptual representation of
each stimulus is modeled as a pattern of activation across
25 sensory units that are each characterized by an
overlapping tuning curve. Each unit is maximally excited by
one specific stimulus, which we call the unit's preferred
stimulus. Specifically, the activation of the $i^\text{th}$
sensory unit on trial $n$ at time $t$ is given by
\begin{equation}
  A_i(n,t) = \text{exp} \left( \frac{-\left[d_{i,S_n(t)}\right]^2}{\sigma^2} \right)
  \label{eq:DSL_activation}
\end{equation}
where $d_{i,S_n(t)}$ is the (Euclidean) distance between the
preferred stimulus value of the $i^\text{th}$ sensory unit
and the value of the stimulus that was presented on trial
$n$ at time $t$, and $\sigma$ is a constant that increases
with perceptual noise.

Because this class of models does not store an explicit
response criterion, it cannot incorporate criterial drift.
It can, however, incorporate perceptual drift. In this case,
the value of the current stimulus used to compute sensory
unit activation (Equation~\ref{eq:DSL_activation}) is
assumed to drift over time according to
\begin{equation}
  S_n(t) = S_n(\text{T}_\text{S}) + \eta_S \epsilon(t),
  \label{eq:stimulus_drift_RL}
\end{equation}
where $\eta_S$ scales the magnitude of the drift and
$\epsilon(t)$ is a noise process.

The model includes two decision or actor units -- one
associated with each of the two possible responses.
Initially, each sensory unit is connected to both actor
units with some random connection strength. Let
$\omega_{iJ}(n)$ denote the strength of the connection
between sensory unit $i$ and actor unit $J$ (for $J$ = A or
B) on trial $n$. Then the activation in actor unit $J$ on
trial $n$ at time $t$, denoted by $V_J(n,t)$, equals
\begin{equation}
  V_J(n,t) = \sum_{i} \omega_{iJ}(n) A_i(n,t).
\end{equation}
A response is selected by comparing the activations in
competing actor units immediately after stimulus
presentation, that is, at time $t=\text{T}_\text{S}$,  using
the following the decision rule:
\begin{equation}
 \text{Respond } R_n =
  \begin{cases}
    A, & \text{if $V_A(n,\text{T}_\text{S}) > V_B(n,\text{T}_\text{S})$}\\
    B, & \text{if $V_A(n,\text{T}_\text{S}) \leq V_B(n,\text{T}_\text{S}).$}
  \end{cases}
\end{equation}

The connection strengths $\omega_{iA}(n)$ and
$\omega_{iB}(n)$ are updated after feedback is received on
each trial according to standard reinforcement learning
rules \parencite{SuttonBarto1998}. If the feedback is
positive, then for J = A or B:
\begin{equation}
  \omega_{i\text{J}}(n) = \omega_{i\text{J}}(n-1) + \frac{\alpha_{actor}}{t_\text{FD}} A_i(n,\text{T}_\text{F}) V_\text{J}(n,\text{T}_\text{F}) \delta(n-1) [1-\omega_{i\text{J}}(n-1)],
  \label{eq:W+}
\end{equation}
where $\alpha_{actor}$ is the learning-rate of the actor,
and $\delta(n-1)$ is the reward prediction error on trial
$n-1$. The last term prevents the weight from exceeding 1.
Note that the increase in synaptic strength is scaled by the
product of the pre- and postsynaptic activation values. Also
note that, as in equation~\ref{RL}, the learning rate is
scaled by the inverse of the feedback delay. If the feedback
is negative, then 
\begin{equation}
  \omega_{i\text{J}}(n) = \omega_{i\text{J}}(n-1) + \frac{\alpha_{actor}}{t_\text{FD}} A_i(n,\text{T}_\text{F}) V_\text{J}(n,\text{T}_\text{F}) \delta(n-1) \omega_{i\text{J}}(n-1).
  \label{eq:W-}
\end{equation}
Now the last term prevents the weight from falling below 0.
Note that on error trials, $\delta(n-1)$ will be negative,
so equation \ref{eq:W-} decreases the synaptic weight.

The reward prediction error on trial $n-1$ is defined as the
value of the obtained reward, denoted by $R(n-1)$ minus the
value of the predicted reward, denoted by $P(n-1)$:
\begin{equation}
  \delta(n-1) = R(n-1) - P(n-1).
\end{equation}
The predicted reward on trial $n$ is determined by the
critic via
\begin{equation}
  P(n) = P(n-1) + \frac{\alpha_{critic}}{t_\text{FD}} \delta(n-1),
  \label{eq:Pcritic}
\end{equation}
where $\alpha_{critic}$ is the learning rate of the critic.
Note that this learning rate is again scaled by the inverse
of the feedback delay. 

Much evidence suggests that this type of stimulus-response
learning is mediated largely within the striatum, and is
facilitated by a dopamine-mediated reinforcement learning
signal that is time dependent
\parencite[e.g.,][]{ValentinMaddoxAshby2014}. Specifically,
the dopamine signal generated by positive feedback appears
to peak at around 500 ms after feedback and then decay back
to baseline levels within 2 or 3 s
\parencite{YagishitaEtAl2014}. As a result, synaptic
plasticity at cortical-striatal synapses is attenuated with
increasing feedback delays \parencite{YagishitaEtAl2014}.
The scaling of $\alpha_{actor}$ and $\alpha_{critic}$ by
$1/{t_\text{FD}}$ is one way to model this phenomenon.
However, it is possible that stimulus-response association
learning is mediated by other brain systems that are less
sensitive to feedback delay. For this reason, we also
investigated a version of the model in which the updating
equations are independent of feedback delay. In this
version, the term $\alpha_{actor}/t_\text{FD}$ is replaced
by $\alpha_{actor}$ in equations \ref{eq:W+} and \ref{eq:W-}
and the term $\alpha_{critic}/t_\text{FD}$ is replaced by
$\alpha_{critic}$ in equation \ref{eq:Pcritic}.

\subsection{Simulation Results}
We investigated how changing the duration of the feedback
delay and the ITI affect criterial learning for each class
of model. More specifically, we simulated performance of
each model in each of the three conditions of the Experiment
1 categorization task. Each simulation continued for 200
trials or until the model responded correctly for 12 trials
in a row. For each set of parameter values, we simulated the
model 100 times and averaged the results, yielding one
observed performance metric measured in mean
trials-to-criterion for each condition. 

Our approach was to generate predictions for each of the
three experimental conditions across a wide range of
parameter values. We then used parameter-space partitioning
(PSP) to evaluate the performance of each model
\parencite{pitt2006global}. Traditional computational
modeling identifies parameter values that allow the model to
provide the best possible fit to the observed data. This
traditional approach therefore treats the single observed
data set being fit as a gold standard. Our goal instead was
to investigate the range of possible predictions of each
model. We were interested in questions such as: can a model
predict any possible outcome or is it constrained to always
predict, for example, that feedback delays impair learning?
PSP was designed to answer such questions.

Classical PSP is defined for non-stochastic models and is
often implemented by exploring the parameter space via a
Markov chain Monte Carlo algorithm. In contrast, we used
brute force search over a grid of plausible parameter
values. Because our models are stochastic, at each sampled
set of parameter values we generated multiple simulations
and classified the results into one of a small set of
qualitative outcome patterns. PSP calculates the proportion
of the parameter space where the model makes specific
predetermined qualitative predictions. We focused on the
following four such predictions. 1) Delay impaired:
Performance is worst in the Feedback-Delay condition. 2)
Long ITI impaired: Performance is worst in the Long-ITI
condition. 3) Short ITI impaired: Performance is worst in
the Control condition. 4) Other: Two or more conditions are
tied for worst performance. For each model, the PSP analysis
quantified the proportions of the explored parameter space
where the model made each of these qualitative predictions.

\subsubsection{Models that assume a stored criterion}
We investigated predictions of these models across a wide
range of values for the parameters $\eta_{x}$, $\eta_{c}$,
and $\alpha$.  Specifically, in the case of $\alpha$,  we
stepped through every value in the interval $[0, .2]$, with
a step size of .01.  In the case of both $\eta_{x}$, and
$\eta_{c}$, we searched over the interval $[0, 5]$, with a
step size of $.1$.  We also explored the binary case of
whether or not the update rate $\alpha$ was scaled by the
feedback delay. 

Figure~\ref{fig:criterion_results} shows the results. Panel
A lists the proportions of parameter space over which the
version of the model that is sensitive to feedback delay
predicts each of the four qualitatively different outcomes.
Note that this model predicts that the poorest performance
will be in the Feedback Delay condition for all values of
its parameters. At first glance, this result seems
surprising because it means that there are no parameter
values that make the model more sensitive to ITI than to
feedback delay. This makes sense though because increasing
the ITI has no effect on the mean criterion value -- the
only effect is to increase the criterion value's variance.
In contrast, increasing the feedback delay affects the mean
criterion value because it slows the criterion updating
process from converging on the optimal value. 

\begin{figure} 
  \centering
  \includegraphics[width=1\textwidth]{../figures/model_new_class_II_yes_stored_criterion.pdf}
  \caption{Simulation results for models that assume a stored criterion.  
      \textbf{A:} The proportions of parameter space where
      each of the four qualitative outcomes is predicted by
      the versions of the model that assume criterion
      updating is sensitive to feedback delay. 
      \textbf{B:} Boxplot showing the parameter ranges that
      produced the panel A results. All parameter values
      were normalized by the largest value in the search
      range, so the ordinate ranges from zero to one for all
      parameters.
      % 
      \textbf{C:} The proportions of parameter space where
      the models that assume criterion updating is
      insensitive to feedback delay predict each of the four
      qualitative outcomes. 
      \textbf{D:} Boxplot showing the parameter ranges that
      produced the panel C results.     
      %
      \textit{Note:} In all panels, color indicates the PSP
      pattern.
}
    \label{fig:criterion_results}
\end{figure}

Panel C of Figure \ref{fig:criterion_results} shows the same
results as in panel A, except for the version of the model
in which the criterion updating process is insensitive to
feedback delay. Note that this version of the model predicts
that performance must be worst in the Long-ITI condition --
again for all values of its parameters. This result also
shows that no amount of perceptual or criterial drift allows
this version of the model to account for the Experiment 1
results. 

\subsubsection{Models that assume no criterion}
We investigated predictions of the SR-learning model by
varying four parameters; namely, the perceptual-noise
variance $\sigma^2$, the stimulus drift parameter $\eta_S$,
and the actor and critic learning rates (i.e.,
$\alpha_{actor}$ and $\alpha_{critic}$, respectively). In
the case of $\sigma$, we searched over the interval $[1,
10]$, with a step size of $3$. For $\eta_S$, we searched
over the interval $[0, 1]$, with a step size of $.1$. For
both $\alpha_{actor}$ and $\alpha_{critic}$, we stepped
through every value in the interval $[0, .2]$, with a step
size of $.02$. We constrained our search over these
parameters to this interval because reinforcement-learning
models are prone to instability at very high learning rates
\parencite{SuttonBarto1998}. As evidence of this, at higher
learning rates, the model failed to learn with any
consistency -- that is, in most cases, it failed to reach
the learning criterion (12 correct responses in a row)
within the allowable 200 trials.   We also explored the
binary case of whether or not the update rates
$\alpha_{actor}$ and $\alpha_{critic}$ were scaled by the
feedback delay. As with the other models, all scores were
normalized by the largest observed value.

The results are described in Figure \ref{fig:RL_results}.
Panel A lists the proportions of parameter space over which
the feedback-delay sensitive version of the model predicts
each qualitatively different outcome. Note that across the
vast majority of its parameter space, this model predicts
that an increase in feedback delay will impair performance
more than an increase in ITI. 

\begin{figure} 
  \centering
  \includegraphics[width=1\textwidth]{../figures/model_new_class_I_no_stored_criterion.pdf}
  \caption{ Simulation results for models that assumed
      stimulus-response learning and therefore no stored
      criterion.  
      \textbf{A:} The proportions of parameter space where
      each of the four qualitative outcomes is predicted by
      the versions of the model that assume synaptic
      updating is sensitive to feedback delay.
      \textbf{B:} Boxplot showing the parameter ranges that
      produced the panel A results.     All parameter values
      were normalized by the largest value in the search
      range, so the ordinate ranges from zero to one for all
      parameters.
      % 
      \textbf{C:} The proportions of parameter space where
      the models that assume synaptic updating is
      insensitive to feedback delay predict each of the four
      qualitative outcomes. 
      \textbf{D:} Boxplot showing the parameter ranges that
      produced the panel C results.     
      %
      \textit{Note:} In all panels, color indicates the PSP
      pattern.
}
  \label{fig:RL_results}
\end{figure}

Figure \ref{fig:RL_results}C shows the proportions of
parameter space over which the models that assume synaptic
updating is insensitive to feedback delay predict each of
the four qualitative outcomes. Surprisingly, this version of
the model also almost always predicts the poorest
performance in the Feedback-Delay condition. What is going
on here? First, note that even if
$\alpha_{actor}/t_\text{FD}$ and
$\alpha_{critic}/t_\text{FD}$ in equations \ref{eq:W+},
\ref{eq:W-}, and \ref{eq:Pcritic} are replaced by
$\alpha_{actor}$ and $\alpha_{critic}$, respectively, then
equations \ref{eq:W+} and \ref{eq:W-} are still sensitive to
feedback delay because the pre- and postsynaptic activations
in equations \ref{eq:W+} and \ref{eq:W-} are computed at the
time of feedback -- that is, at time T$_\text{F}$. So the
longer that the feedback is delayed, the more time there is
for the stimulus representation to drift from its true
value. As a result, this model predicts that delayed
feedback will impair learning, even though the amount of
updating on each trial does not depend on feedback delay.
Second, note that all versions of this model are generally
insensitive to the length of the ITI. The stored-criterion
models are adversely affected by a long ITI because the
criterion drifts during this time and large drift means that
on the next trial a decision will be made with a suboptimal
value of the criterion. But there is no criterion to drift
in the SR-learning models. The stimulus will continue to
drift during the ITI in these models, but with no
consequence, because after the synaptic updating that occurs
with presentation of the feedback, the stimulus
representation on the current trial is no longer needed. So
all versions of the SR-learning model are more sensitive to
feedback delay than to the duration of the ITI. In support
of this interpretation, note from panel D of Figure
\ref{fig:RL_results} that the few versions of the model in
which synaptic updating is insensitive to feedback delay
that predict poorest performance in the Long ITI or Control
conditions all include almost no stimulus drift (i.e.,
$\eta_\text{S}$ is small), which eliminates the one
remaining component of the model that makes it sensitive to
feedback delay.

\subsubsection{Summary of modeling results}
We examined two classes of criterial-learning models that
make different predictions about the effects of feedback
delay and ITI. The first class assumes that the criterion is
stored in memory and compared against incoming stimuli to
generate responses. These models predict poorest performance
in the Feedback-Delay condition only when the update rule is
explicitly delay-sensitive. Otherwise, they make the strong
prediction that performance must be worst in the Long-ITI
condition. The second class of models assumes no stored
criterion, with responding driven instead by reinforcement
learning of SR associations. Almost all versions of this
general model make the strong a priori prediction that
performance must be worst in the Feedback-Delay condition --
even those versions that predict no effect of feedback delay
on the strength of synaptic updating. 

\section{General Discussion}
The notion of a response criterion is ubiquitous in
psychological models of decision making. Despite its
theoretical importance, relatively little is known about its
perceptual and cognitive basis. This article focused on two
strikingly different interpretations of the criterion. The
first, which seems to be assumed implicitly by most
decision-making models -- including for example, signal
detection theory -- is that decisions are made by comparing
the stimulus value to a stored value of the criterion, and
that this stored value is updated trial-by-trial after the
feedback is presented. A second interpretation, which is
motivated by results from the procedural-learning
literature, is that learning instead is a process of
associating responses with stimuli. According to this
account, there is no response criterion -- at least not one
with any mental representation. The value that the first
class of models would refer to as the response criterion is
simply the hypothetical value that separates stimuli
associated with contrasting responses. 

As a first step in testing between these two very different
interpretations, we explored, both empirically and
theoretically, how feedback delays and increases in the ITI
affect criterial learning in a one-dimensional
category-learning task. Our empirical results strongly
suggested that human criterial learning is sensitive to
feedback delay but not to the ITI duration. To investigate
the theoretical implications of this result, we examined
predictions of two qualitatively different types of
computational model. This analysis showed that SR-learning
models almost always predict that feedback delays should
impair learning more than long ITIs, even versions of the
model in which the amount of synaptic updating is
insensitive to feedback delay. In contrast, a broad class of
models that assumed the criterion is learned and updated
trial-by-trial predict that increasing the ITI should have
greater effect than delaying feedback, except for the subset
of these models that explicitly assume the criterial
updating process is sensitive to feedback delay.

In summary, our results suggest that if a criterion is
learned and stored in memory, then its trial-by-trial
updating must be sensitive to feedback delay. How likely is
this model? If a criterion is learned and stored in memory,
then one obvious possibility is that the storage is in
working memory. After all, in the present experiments at
least, the current value of the criterion would need to be
accessed and updated every few seconds -- properties that
are commonly attributed to working memory
\parencite[e.g.,][]{Baddeley2010, Oberauer2002}. One
difficulty with this account is that it is widely accepted
that working memory is largely insensitive to feedback
delay. For example, rule-based category-learning tasks that
are known to recruit working memory and executive attention
are generally unaffected by feedback delays of up to 10 s
\parencite{DunnEtAl2012, ell2009critrial,
MaddoxAshbyBohil2003, MaddoxIng2005,  Worthyetal2013}.
Whereas working memory is generally attributed to circuits
centered in prefrontal cortex
\parencite[e.g.,][]{AshbyEtAl2005, Funahashi2017}, an
alternative possibility is that the criterion is stored in
the cerebellum. For example, the cerebellum has been
associated with working-memory tasks
\parencite[e.g.,][]{AshidaEtAl2019}, and synaptic plasticity
there follows a gradient descent learning rule that is
sensitive to feedback timing \parencite{brudner2016delayed,
held_adaptation_1966, honda_adaptation_2012,
kitazawa_effects_1995, kitazawa_prism_2002}. Our results are
therefore easy to reconcile with this possibility. However,
there is virtually no previous literature linking criterial
learning to the cerebellum, so much more empirical and
theoretical work is needed to establish this as a viable
model.

Whereas the stored-criterion model struggles to  account for
our results, the SR-learning account  is simple and
straightforward. In particular, almost all versions of this
model predict our results -- even those versions that assume
the strength of synaptic updating is unaffected by feedback
delays. Furthermore, there is a well-accepted neural account
of this model. First, there is abundant evidence that the
learning of arbitrary SR associations is mediated primarily
within the striatum \parencite[e.g.,][]{Horvitz2009,
PackardMcGaugh1992}. Second, there is also abundant evidence
that striatal-mediated learning is impaired with feedback
delays as short as 2.5 or 3 s
\parencite{MaddoxAshbyBohil2003, MaddoxIng2005,
YagishitaEtAl2014}.

We are not aware of any other attempts to address directly
the question of whether or not a response criterion is a
fundamental psychological construct. Even so, there are some
results in the category-learning literature that support a
mixed view. The multivariate generalization of a response
criterion is a decision bound that separates
multidimensional stimuli belonging to contrasting categories
\parencite[e.g.,][]{AshbyGott1988}. The multivariate
analogue of the stored-criterion hypothesis is that the
decision bound is learned and stored trial-by-trial in some
form of memory and that categorization decisions are made by
noting which side of the decision bound the current stimulus
is on. A second possibility though is that category-learning
in these tasks is of SR associations, in which case the
decision bound has no psychological meaning and instead is
just the set of percepts that divide the perceptual space
into regions associated with contrasting responses. Although
more research is needed on this question, the current
evidence strongly suggests that both hypotheses are correct,
but that they apply to different types of categorization
tasks.

With rule-based tasks in which the optimal strategy is a
one-dimensional rule (like the tasks used here), the
evidence strongly favors the decision-bound-is-learned
hypothesis, whereas with information-integration tasks in
which the optimal strategy is impossible to describe
verbally and therefore requires some sort of
similarity-based response strategy, the evidence strongly
favors the SR-learning hypothesis
\parencite{AshbyWaldron1999, CasaleEtAl2012}. For example,
if a decision bound is learned, it should be possible to use
this bound to respond to novel stimuli that fall in some
nearby, but untrained region of perceptual space. In
contrast, SR learning builds associations between specific
stimuli and specific responses and would not generalize to
novel stimuli -- at least, not if the novel stimuli are
perceptually distinct. With rule-based categories,
generalization to novel stimuli is nearly perfect -- that
is, responses to novel stimuli are almost perfectly
predicted by the one-dimensional decision bound that best
describes the participant's training performance
\parencite{CasaleEtAl2012}. However, with
information-integration categories, there is no evidence of
any generalization. Instead, performance on novel stimuli is
at chance \parencite{CasaleEtAl2012}. 

Rule-based category learning depends on working memory and
executive attention and is relatively unaffected by feedback
delays as long as 10 s, whereas information-integration
category learning recruits procedural learning and is
impaired by feedback delays as short as 2.5 s \parencite[for
a review of the scores of studies supporting this
hypothesis, see, e.g.,][]{Ashby2025}. Our results suggest
that criterial learning shares the same sensitivity to
feedback delay as information-integration category learning.
Therefore, our results support the hypothesis that criterial
learning, like information-integration category learning, is
a form of procedural learning -- that is, criterial learning
is a form of SR associative learning that is mediated
primarily in the basal ganglia. Similarly, our results are
inconsistent with the hypothesis that criterial learning
depends in any significant way on working memory and/or
executive attention. 

Criterial learning is among the most classic and ubiquitous
of all cognitive skills. For example, signal-detection
theory teaches that it is the central form of learning in an
enormous range of decision-making tasks -- everything from
simple YES-NO detection of a weak signal to assessing the
guilt or innocence of a defendant in a jury trial. Our
results suggest that even in simple rule-based tasks,
criterial learning seems to be subserved, at least in part,
by associative mechanisms. Most current theories tend to
classify tasks as either executive function (e.g.,
rule-based category learning) or procedural (e.g., mirror
tracing). Our results suggest that such classification
schemes might oversimplify how humans perform these tasks,
and therefore that much more work is needed to understand
how different learning and memory systems interact.

\section{Transparency and Openness}
All data have been made publicly available in the following
GitHub repository:
\url{https://github.com/crossley/crit_learn_delay}

\section{Author Notes}
Preparation of this article was supported by Public Health
Service Grant MH2R01-063760.

\printbibliography

\end{document}

